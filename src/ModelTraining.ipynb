{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "loaded_data = pd.read_csv('../data/topic21_v23_train.csv')\n",
    "\n",
    "loaded_data.info()"
   ],
   "id": "aba8bd5ff37bfc3c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def remove_outliers(df, threshold=2.5):\n",
    "    df_clean = df.copy()\n",
    "    initial_rows = len(df)\n",
    "    numeric_cols = df_clean.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        Q1 = df_clean[col].quantile(0.25)\n",
    "        Q3 = df_clean[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - threshold * IQR\n",
    "        upper_bound = Q3 + threshold * IQR\n",
    "        df_clean = df_clean[(df_clean[col] >= lower_bound) & (df_clean[col] <= upper_bound)]\n",
    "\n",
    "    removed_rows = initial_rows - len(df_clean)\n",
    "    print(f\"Removed {removed_rows} rows ({(removed_rows / initial_rows) * 100:.2f}% of data)\")\n",
    "\n",
    "    return df_clean\n"
   ],
   "id": "d726b946f468b963",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "loaded_data = loaded_data.dropna(subset=['0', '1', '2', '3', '4'])\n",
    "# loaded_data = loaded_data.dropna()\n",
    "loaded_data = remove_outliers(loaded_data)\n",
    "\n",
    "loaded_data.info()"
   ],
   "id": "52a7da4e496b9130",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = loaded_data.copy()\n",
    "\n",
    "def extract_range_mean(val):\n",
    "    try:\n",
    "        nums = [int(s) for s in val.replace('cc','').replace('HP','').split('-')]\n",
    "        return np.mean(nums)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "df['engine_capacity'] = df['engine_capacity_cc'].apply(extract_range_mean)\n",
    "df['horsepower_val'] = df['horsepower'].apply(extract_range_mean)\n",
    "df.drop(columns=['engine_capacity_cc', 'horsepower'], inplace=True)\n",
    "\n",
    "for col in ['brand', 'model', 'trim']:\n",
    "    means = df.groupby(col)['price'].mean()\n",
    "    df[col + '_enc'] = df[col].map(means)\n",
    "\n",
    "df.drop(columns=['brand', 'model', 'trim'], inplace=True)\n",
    "\n",
    "df.info()"
   ],
   "id": "98a38747bb6e629f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X = df.drop(columns=['price'])\n",
    "y = df['price']\n",
    "\n",
    "# X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f'X_train shape = {X_train.shape}')"
   ],
   "id": "40a4b26e55237399",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# y_train = np.log1p(y_train)",
   "id": "1bd8513461d43392",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "numerical_features = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(\"Numerical features:\", numerical_features)\n",
    "print(\"Categorical features:\", categorical_features)"
   ],
   "id": "aeec3246b05f5391",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "\n",
    "X_train_transformed = pipeline.fit_transform(X_train)\n",
    "X_valid_transformed = pipeline.transform(X_valid)\n"
   ],
   "id": "52e6cb480749a2ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, ExtraTreesRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "models = {\n",
    "    \"SVR\": SVR(),\n",
    "    \"RandomForest\": RandomForestRegressor(random_state=42),\n",
    "    \"ExtraTrees\": ExtraTreesRegressor(random_state=42),\n",
    "    \"XGBoost\": XGBRegressor(verbosity=0, random_state=42),\n",
    "    \"CatBoost\": CatBoostRegressor(verbose=0, random_state=42),\n",
    "\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"ElasticNet\": ElasticNet(),\n",
    "    \"DecisionTree\": DecisionTreeRegressor(),\n",
    "\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(),\n",
    "    \"AdaBoost\": AdaBoostRegressor(),\n",
    "    \"KNeighbors\": KNeighborsRegressor(),\n",
    "    \"MLP\": MLPRegressor(max_iter=1000),\n",
    "    \"LightGBM\": LGBMRegressor()\n",
    "}"
   ],
   "id": "375d7f00f13f23dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def train_and_evaluate(models, X_train, y_train, X_valid, y_valid):\n",
    "    results = {}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"Training {name}...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_valid)\n",
    "\n",
    "        # predictions = np.expm1(predictions)\n",
    "\n",
    "        mse = mean_squared_error(y_valid, predictions)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_valid, predictions)\n",
    "        r2 = r2_score(y_valid, predictions)\n",
    "\n",
    "        results[name] = {\n",
    "            \"MSE\": mse,\n",
    "            \"RMSE\": rmse,\n",
    "            \"MAE\": mae,\n",
    "            \"R2\": r2\n",
    "        }\n",
    "    return results\n"
   ],
   "id": "3aa16a221973c945",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results = train_and_evaluate(models, X_train_transformed, y_train, X_valid_transformed, y_valid)\n",
    "results_df = pd.DataFrame(results).T.sort_values(by=\"RMSE\")\n",
    "print(results_df)\n",
    "\n",
    "                       # MSE           RMSE           MAE        R2\n",
    "# CatBoost          3.326862e+09   57678.957622  36007.046475  0.758468\n",
    "# ExtraTrees        3.819171e+09   61799.445123  35492.232677  0.722726\n",
    "# XGBoost           3.909158e+09   62523.258776  38381.046875  0.716193\n",
    "# RandomForest      4.318880e+09   65718.189933  40911.319177  0.686447\n",
    "# LightGBM          4.398064e+09   66317.904008  41307.707782  0.680698\n",
    "# Ridge             4.408645e+09   66397.624660  42431.725407  0.679930\n",
    "# KNeighbors        4.446898e+09   66685.066571  39663.771807  0.677153\n",
    "# Lasso             5.004806e+09   70744.652976  43656.288867  0.636648\n",
    "# LinearRegression  5.177776e+09   71956.763602  44429.458294  0.624090\n",
    "# GradientBoosting  5.320518e+09   72941.880798  49072.349349  0.613727\n",
    "# MLP               7.663219e+09   87539.812380  60137.373434  0.443646\n",
    "# DecisionTree      8.649014e+09   93000.074119  52714.455061  0.372077\n",
    "# ElasticNet        9.665076e+09   98311.118872  70419.732800  0.298310\n",
    "# AdaBoost          1.062364e+10  103071.064253  77921.810713  0.228717\n",
    "# SVR               1.559393e+10  124875.649262  84389.552462 -0.132128\n"
   ],
   "id": "d48c63ceeb1cc93a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.svm import SVR\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestRegressor(random_state=42),\n",
    "    \"ExtraTrees\": ExtraTreesRegressor(random_state=42),\n",
    "    \"CatBoost\": CatBoostRegressor(verbose=0, random_state=42),\n",
    "    \"XGBoost\": XGBRegressor(verbosity=0, random_state=42)\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    \"RandomForest\": {\n",
    "        'pca__n_components': [5, 10, 15, 19],\n",
    "        'model__n_estimators': [100, 300, 500, 800],\n",
    "        'model__max_depth': [None, 10, 20, 30, 50],\n",
    "        'model__min_samples_split': [2, 5, 10],\n",
    "        'model__min_samples_leaf': [1, 2, 4],\n",
    "        'model__max_features': ['sqrt', 'log2', None]\n",
    "    },\n",
    "    \"ExtraTrees\": {\n",
    "        'pca__n_components': [5, 10, 15, 19],\n",
    "        'model__n_estimators': [100, 300, 500, 800],\n",
    "        'model__max_depth': [None, 10, 20, 30, 50],\n",
    "        'model__min_samples_split': [2, 5, 10],\n",
    "        'model__min_samples_leaf': [1, 2, 4],\n",
    "        'model__max_features': ['sqrt', 'log2', None]\n",
    "    },\n",
    "    \"CatBoost\": {\n",
    "        'pca__n_components': [5, 10, 15, 19],\n",
    "        'model__iterations': [500, 1000],\n",
    "        'model__depth': [4, 6, 8, 10],\n",
    "        'model__learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "        'model__l2_leaf_reg': [1, 3, 5, 7, 9],\n",
    "        'model__bagging_temperature': [0, 0.5, 1]\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        'pca__n_components': [5, 10, 15, 19],\n",
    "        'model__n_estimators': [100, 300, 500, 800],\n",
    "        'model__max_depth': [3, 5, 7, 10],\n",
    "        'model__learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "        'model__subsample': [0.6, 0.8, 1.0],\n",
    "        'model__colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'model__gamma': [0, 0.1, 0.3, 0.5],\n",
    "        'model__reg_alpha': [0, 0.1, 1],\n",
    "        'model__reg_lambda': [1, 1.5, 2]\n",
    "    }\n",
    "}\n"
   ],
   "id": "a99d2cf2846faa00",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "preds = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n GridSearch for {name}...\")\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('pca', PCA()),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=param_grids[name],\n",
    "        cv=5,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        verbose=2,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X_train_transformed, y_train)\n",
    "\n",
    "    print(f\" Best params for {name}:\")\n",
    "    print(grid_search.best_params_)\n",
    "    print(f\" Best CV score (neg MSE): {-grid_search.best_score_:.4f}\")\n",
    "\n",
    "    best_pipeline = grid_search.best_estimator_\n",
    "\n",
    "    cv_scores = cross_val_score(\n",
    "        best_pipeline,\n",
    "        X_train_transformed,\n",
    "        y_train,\n",
    "        cv=5,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    print(f\" Final 5-fold CV RMSE (log scale): {(-cv_scores.mean()) ** 0.5:.4f} ± {cv_scores.std() ** 0.5:.4f}\")\n",
    "\n",
    "    y_pred_log = best_pipeline.predict(X_valid_transformed)\n",
    "\n",
    "    y_pred = np.expm1(y_pred_log)\n",
    "\n",
    "    rmse = mean_squared_error(y_valid, y_pred)\n",
    "    r2 = r2_score(y_valid, y_pred)\n",
    "\n",
    "    print(f\"{name} on Validation:\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"R²:   {r2:.4f}\")\n",
    "\n",
    "    preds[name] = y_pred"
   ],
   "id": "36024afe4ab90d31",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
